{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e24cff-71db-4f79-b079-10a50ba6bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import yake\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "from safetensors.torch import load_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb630d8c-d125-4175-9b16-ed71f8178c12",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b5042e83-0a6b-4190-93b5-e76bf3c245f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKETID</th>\n",
       "      <th>ALTERNATEKEYSUFFIX</th>\n",
       "      <th>AREA</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>ISSUE</th>\n",
       "      <th>RECEIVEDDATE</th>\n",
       "      <th>COMPLETEDDATE</th>\n",
       "      <th>SUBJECT</th>\n",
       "      <th>URGENCYCODE</th>\n",
       "      <th>PROBLEM</th>\n",
       "      <th>SOLUTION</th>\n",
       "      <th>RESULTIONSUMMARY</th>\n",
       "      <th>ACCOUNTID</th>\n",
       "      <th>ACCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t6UJ9A00GHH8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1000v4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-23 11:30:32</td>\n",
       "      <td>2025-05-23 16:05:51</td>\n",
       "      <td>URGENT HELP NEEDED: PI 7268 Batch posting fail...</td>\n",
       "      <td>3</td>\n",
       "      <td>Would you be able to help correct the whatever...</td>\n",
       "      <td>Batch had been imported incorrectly. Corrected...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A6UJ9A0023H4</td>\n",
       "      <td>Account_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t6UJ9A00GFTK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1000v4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-08 14:38:09</td>\n",
       "      <td>2025-05-23 15:11:47</td>\n",
       "      <td>MUK - WIP Report</td>\n",
       "      <td>3</td>\n",
       "      <td>Hi, \\n\\nPlease see attachment of our  report t...</td>\n",
       "      <td>I advised  to run the  report in WOP Reports w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A6UJ9A0009N9</td>\n",
       "      <td>Account_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t6UJ9A00GGSG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1000v4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-19 07:02:04</td>\n",
       "      <td>2025-05-23 14:39:32</td>\n",
       "      <td>invoices into the GL</td>\n",
       "      <td>3</td>\n",
       "      <td>Hi,\\n\\nThere is a process that my team do and ...</td>\n",
       "      <td>user is not set up as a pop user so currently ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A6UJ9A000H3R</td>\n",
       "      <td>Account_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t6UJ9A00GHDL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1000v4</td>\n",
       "      <td>BACS</td>\n",
       "      <td>2025-05-22 14:37:44</td>\n",
       "      <td>2025-05-23 14:34:00</td>\n",
       "      <td>BACS query</td>\n",
       "      <td>1</td>\n",
       "      <td>when I raise a BACS, does it have to be raised...</td>\n",
       "      <td>Advised that the remittance date entered when ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A6UJ9A0083J7</td>\n",
       "      <td>Account_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t6UJ9A00GHHG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S1000v4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-05-23 12:20:29</td>\n",
       "      <td>2025-05-23 12:56:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>,\\n\\nCan you please set up  as a new timesheet...</td>\n",
       "      <td>set up via Contracting -  -</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A00SWA300000</td>\n",
       "      <td>Account_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TICKETID  ALTERNATEKEYSUFFIX  AREA CATEGORY ISSUE        RECEIVEDDATE  \\\n",
       "0  t6UJ9A00GHH8                 NaN   NaN  S1000v4   NaN 2025-05-23 11:30:32   \n",
       "1  t6UJ9A00GFTK                 NaN   NaN  S1000v4   NaN 2025-05-08 14:38:09   \n",
       "2  t6UJ9A00GGSG                 NaN   NaN  S1000v4   NaN 2025-05-19 07:02:04   \n",
       "3  t6UJ9A00GHDL                 NaN   NaN  S1000v4  BACS 2025-05-22 14:37:44   \n",
       "4  t6UJ9A00GHHG                 NaN   NaN  S1000v4   NaN 2025-05-23 12:20:29   \n",
       "\n",
       "        COMPLETEDDATE                                            SUBJECT  \\\n",
       "0 2025-05-23 16:05:51  URGENT HELP NEEDED: PI 7268 Batch posting fail...   \n",
       "1 2025-05-23 15:11:47                                   MUK - WIP Report   \n",
       "2 2025-05-23 14:39:32                               invoices into the GL   \n",
       "3 2025-05-23 14:34:00                                         BACS query   \n",
       "4 2025-05-23 12:56:26                                                NaN   \n",
       "\n",
       "   URGENCYCODE                                            PROBLEM  \\\n",
       "0            3  Would you be able to help correct the whatever...   \n",
       "1            3  Hi, \\n\\nPlease see attachment of our  report t...   \n",
       "2            3  Hi,\\n\\nThere is a process that my team do and ...   \n",
       "3            1  when I raise a BACS, does it have to be raised...   \n",
       "4            3  ,\\n\\nCan you please set up  as a new timesheet...   \n",
       "\n",
       "                                            SOLUTION RESULTIONSUMMARY  \\\n",
       "0  Batch had been imported incorrectly. Corrected...              NaN   \n",
       "1  I advised  to run the  report in WOP Reports w...              NaN   \n",
       "2  user is not set up as a pop user so currently ...              NaN   \n",
       "3  Advised that the remittance date entered when ...              NaN   \n",
       "4                        set up via Contracting -  -              NaN   \n",
       "\n",
       "      ACCOUNTID    ACCOUNT  \n",
       "0  A6UJ9A0023H4  Account_1  \n",
       "1  A6UJ9A0009N9  Account_2  \n",
       "2  A6UJ9A000H3R  Account_3  \n",
       "3  A6UJ9A0083J7  Account_4  \n",
       "4  A00SWA300000  Account_5  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data import\n",
    "\n",
    "data_folder = Path.cwd().joinpath('Data')\n",
    "\n",
    "tickets_df = pd.read_excel(data_folder.joinpath('tickets_cleaned.xlsx'))\n",
    "tickets_history_df = pd.read_excel(data_folder.joinpath('ticket_history.xlsx'))\n",
    "\n",
    "with open(data_folder.joinpath('ticket_template_query.txt')) as tq, \\\n",
    "    open(data_folder.joinpath('ticket_template_answer.txt')) as ta, \\\n",
    "        open(data_folder.joinpath('ticket_template_his.txt')) as th:\n",
    "\n",
    "        query_template = tq.read()\n",
    "        answer_template = ta.read()\n",
    "        history_template = th.read()\n",
    "\n",
    "tickets_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b67fc3-a76c-4384-9d45-bfd7a9d35005",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0ae3f42-face-4dc2-97ce-9923b982e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data preprocessing functions\n",
    "\n",
    "# Apply basic NLP preprocessing\n",
    "\n",
    "def preprocess_ticket(text, spell_checker = None, keyword_extractor = None, spacy_nlp = None,\n",
    "                         whitespace_cleaning = False, typo_correction = False,\n",
    "                             keyword_extraction = False, ner = False):\n",
    "\n",
    "    text_dict = {}\n",
    "    \n",
    "    # Whitespace cleanup\n",
    "\n",
    "    if whitespace_cleaning:\n",
    "\n",
    "        text = re.sub(r'\\s+', lambda m: '\\n' if '\\n' in m.group() else ' ', text.strip())\n",
    "    \n",
    "    # Typo correction\n",
    "\n",
    "    if typo_correction and spell_checker is not None:\n",
    "        \n",
    "        corrected_words = []\n",
    "        for word in cleaned.split():\n",
    "            # Keep numbers, codes, and certain technical terms unchanged\n",
    "            if re.match(r'^[A-Za-z0-9._-]+$', word):\n",
    "                corrected_words.append(spell_checker.correction(word) or word)\n",
    "            else:\n",
    "                corrected_words.append(word)\n",
    "        corrected_text = ' '.join(corrected_words)\n",
    "        text = corrected_text\n",
    "\n",
    "    text_dict['text'] = text \n",
    "    \n",
    "    # Keyword extraction\n",
    "\n",
    "    if keyword_extraction and keyword_extractor is not None:\n",
    "        \n",
    "        keywords = [kw for kw, score in keyword_extractor.extract_keywords(text)]\n",
    "        text_dict['keywords'] = ', '.join(keywords)\n",
    "    \n",
    "    # Named Entity Recognition\n",
    "\n",
    "    if ner and spacy_nlp is not None:\n",
    "        \n",
    "        doc = spacy_nlp(text)\n",
    "        entities = [ent.text + ' - ' + ent.label_ for ent in doc.ents]\n",
    "        text_dict['entities'] = ', '.join(entities)\n",
    "    \n",
    "    return pd.Series(text_dict)\n",
    "\n",
    "# Apply textual templates for structured query-answer pairs\n",
    "\n",
    "def aggregate_history(df, hist_col, date_col, ticket_col, activity_type_col, template,\n",
    "                      remove_tokens = True, ascending_hist = False, exclusion_list = ['Ticket Acknow']):\n",
    "\n",
    "    # Ensure chronological sorting within each ticket and perform filtering\n",
    "    \n",
    "    df = df[~((df[activity_type_col] == 'E-mail') & (df[hist_col].str.len() <= 139))]\n",
    "    df = df[~df[hist_col].isna()]\n",
    "    df = df[~df[activity_type_col].isin(exclusion_list)].reset_index(drop = True)\n",
    "    df = df.sort_values(by = [ticket_col, date_col], ascending = [True, ascending_hist])\n",
    "\n",
    "    df[hist_col] = df[hist_col].fillna('').str.replace(r'(\\S)\\1{2,}', '', regex = True)\n",
    "    df[hist_col] = df[hist_col].apply(lambda text: re.sub(r'\\s+', lambda m: '\\n' if '\\n' in m.group() else ' ', str(text).strip()))\n",
    "    \n",
    "    # Apply the template to each row\n",
    "    \n",
    "    df['FORMATTEDDESC'] = df.apply(lambda x: template.format(\n",
    "        created_date = x[date_col],\n",
    "        activity = x[activity_type_col],\n",
    "        a_desc = x[hist_col]), axis = 1)\n",
    "    \n",
    "    # Group by ticket and aggregate formatted texts with newline separation\n",
    "    \n",
    "    df_grouped_his = (\n",
    "        df.groupby(ticket_col, as_index = False)['FORMATTEDDESC']\n",
    "        .apply(lambda texts: '\\n\\n'.join(texts))\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "\n",
    "    if remove_tokens:\n",
    "\n",
    "        pattern1 = r'(?:\\[REDACTED_[A-Z]+\\][\\s\\W]+){1,}\\[REDACTED_[A-Z]+\\]'\n",
    "        pattern2 = r'E-mail to:.*?\\S*#\\s*\\d+.*?has changed its status to\\s+\\w+'\n",
    "        df_grouped_his['FORMATTEDDESC'] = df_grouped_his['FORMATTEDDESC'].fillna('').str.replace(pattern1, '', regex = True)\n",
    "        df_grouped_his['FORMATTEDDESC'] = df_grouped_his['FORMATTEDDESC'].str.replace(r'(\\n)\\1{2,}', r'\\1\\1', regex = True)\n",
    "        df_grouped_his['FORMATTEDDESC'] = df_grouped_his['FORMATTEDDESC'].str.replace(pattern2, '', regex = True)\n",
    "        \n",
    "    return df_grouped_his\n",
    "\n",
    "# Define a function that prepares a dataset\n",
    "\n",
    "def structure_tickets(tickets_df, his_tickets_df,\n",
    "                      ticket_col, subject_col, cat_col, issue_type_col, received_date_col, query_col, query_template,\n",
    "                      urgency_col, res_sum_col, solution_col, answer_template,\n",
    "                      his_col, his_date_col, his_activity_type_col, his_template,\n",
    "                      spell_checker = None, keyword_extractor = None, spacy_nlp = None,\n",
    "                      ascending_hist = False, exclusion_list = ['Ticket Acknow']):\n",
    "\n",
    "    tickets_df = tickets_df[~tickets_df[query_col].isna()].reset_index(drop = True)\n",
    "\n",
    "    tickets_df[[query_col, query_col + '_keywords']] = \\\n",
    "        tickets_df[query_col].fillna('').apply(lambda x: preprocess_ticket(x,\n",
    "            spell_checker = spell_checker, keyword_extractor = keyword_extractor, spacy_nlp = spacy_nlp,\n",
    "            whitespace_cleaning = True, typo_correction = False, keyword_extraction = True, ner = False))\n",
    "\n",
    "    tickets_df[[solution_col, solution_col + '_keywords']] = \\\n",
    "        tickets_df[solution_col].fillna('').apply(lambda x: preprocess_ticket(x,\n",
    "            spell_checker = spell_checker, keyword_extractor = keyword_extractor, spacy_nlp = spacy_nlp,\n",
    "            whitespace_cleaning = True, typo_correction = False, keyword_extraction = True, ner = False))\n",
    "\n",
    "    his_tickets_agg_df = aggregate_history(his_tickets_df, his_col, his_date_col,\n",
    "                                           ticket_col, his_activity_type_col, his_template,\n",
    "                                           remove_tokens = True,\n",
    "                                           ascending_hist = ascending_hist,\n",
    "                                           exclusion_list = exclusion_list)\n",
    "\n",
    "    tickets_df = tickets_df.merge(his_tickets_agg_df, on = ticket_col, how = 'left')\n",
    "\n",
    "    tickets_df['STRUCTURED' + query_col] = \\\n",
    "        tickets_df.apply(lambda x: query_template.format(\n",
    "            tid = x[ticket_col],\n",
    "            subject = x[subject_col],\n",
    "            cat = x[cat_col],\n",
    "            issue_type = x[issue_type_col],\n",
    "            received_date = x[received_date_col],\n",
    "            keywords = x[query_col + '_keywords'],\n",
    "            problem = x[query_col]), axis = 1)\n",
    "\n",
    "    tickets_df['STRUCTURED' + solution_col] = \\\n",
    "        tickets_df.apply(lambda x: answer_template.format(\n",
    "            urgency = x[urgency_col],\n",
    "            res_sum = x[res_sum_col],\n",
    "            keywords = x[solution_col + '_keywords'],\n",
    "            solution = x[solution_col],\n",
    "            ticket_status_his = x['FORMATTEDDESC']), axis = 1)\n",
    "\n",
    "    return tickets_df[[ticket_col, query_col, solution_col, 'STRUCTURED' + query_col, 'STRUCTURED' + solution_col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2482bed2-a753-4b4e-9444-03bf1d0c6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations and save the data\n",
    "\n",
    "keyword_extractor = yake.KeywordExtractor(n = 2, top = 10)\n",
    "\n",
    "processed_tickets_df = \\\n",
    "    structure_tickets(tickets_df, tickets_history_df,\n",
    "        ticket_col = 'TICKETID', subject_col = 'SUBJECT', cat_col = 'CATEGORY',\n",
    "        issue_type_col = 'ISSUE', received_date_col = 'RECEIVEDDATE', query_col = 'PROBLEM',\n",
    "        urgency_col = 'URGENCYCODE', res_sum_col = 'RESULTIONSUMMARY', solution_col = 'SOLUTION',\n",
    "        his_col = 'ACTIVITYDESC', his_date_col = 'CREATEDATE', his_activity_type_col = 'ACTIVITYTYPE',\n",
    "        query_template = query_template, answer_template = answer_template, his_template = history_template,\n",
    "        keyword_extractor = keyword_extractor, ascending_hist = False, exclusion_list = ['Ticket Acknow'])\n",
    "\n",
    "processed_tickets_df.to_json(data_folder.joinpath('processed_tickets_df.json'),\n",
    "                                 orient = 'index', double_precision = 15, index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7056dc5-1643-4540-a392-59083721098c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKETID</th>\n",
       "      <th>PROBLEM</th>\n",
       "      <th>SOLUTION</th>\n",
       "      <th>STRUCTUREDPROBLEM</th>\n",
       "      <th>STRUCTUREDSOLUTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t6UJ9A00GHH8</td>\n",
       "      <td>Would you be able to help correct the whatever...</td>\n",
       "      <td>Batch had been imported incorrectly. Corrected...</td>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHH8\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t6UJ9A00GFTK</td>\n",
       "      <td>Hi,\\nPlease see attachment of our report that ...</td>\n",
       "      <td>I advised to run the report in WOP Reports whi...</td>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GFTK\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t6UJ9A00GGSG</td>\n",
       "      <td>Hi,\\nThere is a process that my team do and I ...</td>\n",
       "      <td>user is not set up as a pop user so currently ...</td>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GGSG\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t6UJ9A00GHDL</td>\n",
       "      <td>when I raise a BACS, does it have to be raised...</td>\n",
       "      <td>Advised that the remittance date entered when ...</td>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHDL\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 1\\n  Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t6UJ9A00GHHG</td>\n",
       "      <td>,\\nCan you please set up as a new timesheet re...</td>\n",
       "      <td>set up via Contracting - -</td>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHHG\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TICKETID                                            PROBLEM  \\\n",
       "0  t6UJ9A00GHH8  Would you be able to help correct the whatever...   \n",
       "1  t6UJ9A00GFTK  Hi,\\nPlease see attachment of our report that ...   \n",
       "2  t6UJ9A00GGSG  Hi,\\nThere is a process that my team do and I ...   \n",
       "3  t6UJ9A00GHDL  when I raise a BACS, does it have to be raised...   \n",
       "4  t6UJ9A00GHHG  ,\\nCan you please set up as a new timesheet re...   \n",
       "\n",
       "                                            SOLUTION  \\\n",
       "0  Batch had been imported incorrectly. Corrected...   \n",
       "1  I advised to run the report in WOP Reports whi...   \n",
       "2  user is not set up as a pop user so currently ...   \n",
       "3  Advised that the remittance date entered when ...   \n",
       "4                         set up via Contracting - -   \n",
       "\n",
       "                                   STRUCTUREDPROBLEM  \\\n",
       "0  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHH8\\...   \n",
       "1  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GFTK\\...   \n",
       "2  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GGSG\\...   \n",
       "3  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHDL\\...   \n",
       "4  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHHG\\...   \n",
       "\n",
       "                                  STRUCTUREDSOLUTION  \n",
       "0  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...  \n",
       "1  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...  \n",
       "2  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...  \n",
       "3  Solution metadata:\\n \\n  Urgency code: 1\\n  Re...  \n",
       "4  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tickets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8d378-a555-48b9-a27e-d8439183dc93",
   "metadata": {},
   "source": [
    "## LLM-based processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49140318-88a7-4e6a-b65f-3a1e2c9419bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loading function\n",
    "\n",
    "def load_model(model_path, device, load_8bit = False, from_pretrained = True, is_dummy = False,\n",
    "                   dummy_parameters = {}, rope_scaling = None, max_context_length = None, rope_theta = None):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only = True)\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    gen_config = GenerationConfig.from_pretrained(model_path)\n",
    "\n",
    "    if type(max_context_length) == int:\n",
    "        setattr(gen_config, 'max_length', max_context_length)\n",
    "\n",
    "    if from_pretrained:\n",
    "    \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            device_map = 'auto' if device == torch.device('cuda') else None,\n",
    "            torch_dtype = torch.bfloat16 if device == torch.device('cuda') else torch.float32,\n",
    "            load_in_8bit = load_8bit,\n",
    "            local_files_only = True,\n",
    "            use_safetensors = True,\n",
    "            rope_scaling = rope_scaling\n",
    "        ).to(device)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Pulling out the config\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_path, local_files_only = True, use_safetensors = True)\n",
    "        strict_loading = not is_dummy\n",
    "        \n",
    "        # Optional config editing for a dummy model\n",
    "        \n",
    "        if is_dummy:\n",
    "            for name, value in dummy_parameters.items():\n",
    "                setattr(config, name, value)\n",
    "\n",
    "        if type(rope_scaling) == dict:\n",
    "            setattr(config, 'rope_scaling', rope_scaling)\n",
    "\n",
    "        if type(max_context_length) == int:\n",
    "            setattr(config, 'max_position_embeddings', max_context_length)\n",
    "\n",
    "        if rope_theta is not None:\n",
    "            setattr(config, 'rope_theta', rope_theta)\n",
    "        \n",
    "        # Instantiate the model\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_config(config).to(device)\n",
    "        \n",
    "        # Load parameters\n",
    "        \n",
    "        with open(model_path.joinpath('model.safetensors.index.json'), 'r') as file:\n",
    "            index = json.load(file)\n",
    "        \n",
    "        safetensors_params_map = defaultdict(list)\n",
    "        for param_name, safetensor_name in index['weight_map'].items():\n",
    "            safetensors_params_map[safetensor_name].appendf(param_name)\n",
    "\n",
    "        full_state_dict = {}\n",
    "        \n",
    "        for safetensor_name, param_names in safetensors_params_map.items():\n",
    "            safetensor_path = model_path.joinpath(safetensor_name)\n",
    "            shard_dict = load_file(safetensor_path)\n",
    "            model_dict = model.state_dict()\n",
    "        \n",
    "            shard_dict = {\n",
    "                key : value for key, value in shard_dict.items()\n",
    "                if key in model_dict and model_dict[key].shape == value.shape\n",
    "            }\n",
    "\n",
    "            full_state_dict.update(shard_dict)\n",
    "        \n",
    "        with warnings.catch_warnings(action = 'ignore'):\n",
    "            model.load_state_dict(full_state_dict, strict = strict_loading)\n",
    "\n",
    "        # Parallelize if possible\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = model.to(device)\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "    return tokenizer, model, gen_config\n",
    "    \n",
    "\n",
    "# Define batch inference function\n",
    "\n",
    "def batch_inference_llama(model, tokenizer, df, query_column, answer_column, instruction_prompt, gen_config,\n",
    "                              examples = None, batch_size = 4, max_new_tokens = 1024, num_examples = 1):\n",
    "    \n",
    "    results = []\n",
    "    max_context_len = gen_config.max_length\n",
    "\n",
    "    orig_model = model.module if hasattr(model, 'module') else model\n",
    "    \n",
    "    # Iterate over batches\n",
    "    \n",
    "    for start in tqdm(range(0, len(df), batch_size)):\n",
    "\n",
    "        conversation = []\n",
    "        batch_texts_truncated = []\n",
    "        \n",
    "        # Build few-shot prompt\n",
    "\n",
    "        random.shuffle(examples)\n",
    "        \n",
    "        if examples:\n",
    "            for i in range(num_examples):\n",
    "                conversation.append({'role' : 'user', 'content' : examples[i][0]})\n",
    "                conversation.append({'role' : 'assistant', 'content' : examples[i][1]})\n",
    "    \n",
    "        # System role\n",
    "        \n",
    "        conversation.insert(0, {'role' : 'system', 'content' : instruction_prompt})\n",
    "    \n",
    "        # Tokenize static context\n",
    "        \n",
    "        static_context_tokens = tokenizer.apply_chat_template(\n",
    "            conversation = conversation,\n",
    "            add_generation_prompt = True,\n",
    "            tokenize = True\n",
    "        )\n",
    "        static_token_count = len(static_context_tokens)\n",
    "\n",
    "        \n",
    "        batch_texts = (df[query_column].iloc[start:start+batch_size] + '\\n\\n' +\n",
    "                           df[answer_column].iloc[start:start+batch_size]).tolist()\n",
    "\n",
    "        # Ensure a correct context length\n",
    "\n",
    "        for text in batch_texts:\n",
    "\n",
    "            text_tokens = tokenizer(text.strip(), return_tensors = 'pt')\n",
    "            text_len = text_tokens.input_ids.shape[1]\n",
    "\n",
    "            # Check if adding this text would exceed max context\n",
    "    \n",
    "            if static_token_count + text_len + max_new_tokens > max_context_len:\n",
    "\n",
    "                allowed_len = max_context_len - static_token_count - max_new_tokens\n",
    "                truncated_ids = text_tokens.input_ids[:, :allowed_len]\n",
    "                truncated_text = tokenizer.decode(truncated_ids[0], skip_special_tokens = True)\n",
    "                batch_texts_truncated.append(truncated_text)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                batch_texts_truncated.append(text)\n",
    "        \n",
    "        # Build prompts for batch\n",
    "        \n",
    "        prompts = [\n",
    "            tokenizer.apply_chat_template(\n",
    "                conversation = conversation + [{'role' : 'user', 'content': text.strip()}],\n",
    "                add_generation_prompt = True,\n",
    "                tokenize = False) \\\n",
    "            for text in batch_texts_truncated\n",
    "        ]\n",
    "        \n",
    "        # Tokenize\n",
    "        \n",
    "        inputs = tokenizer(prompts, return_tensors = 'pt',\n",
    "                               padding = True, padding_side = 'left',\n",
    "                                   truncation = False).to(orig_model.device)\n",
    "        \n",
    "        # Generate outputs\n",
    "\n",
    "        orig_model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = orig_model.generate(\n",
    "                **inputs,\n",
    "                pad_token_id = tokenizer.pad_token_id,\n",
    "                generation_config = gen_config,\n",
    "                return_dict_in_generate = True,\n",
    "                use_cache = True,\n",
    "                max_new_tokens = max_new_tokens\n",
    "            )\n",
    "        \n",
    "        decoded_outputs = tokenizer.batch_decode(outputs.sequences, skip_special_tokens = False)\n",
    "        \n",
    "        # Extract only the part after assistant generation\n",
    "        \n",
    "        cleaned_outputs = []\n",
    "        for full_text in decoded_outputs:\n",
    "            if '<|start_header_id|>assistant<|end_header_id|>' in full_text:\n",
    "                cleaned_outputs.append(full_text.split('<|start_header_id|>assistant<|end_header_id|>')[-1].strip())\n",
    "            else:\n",
    "                cleaned_outputs.append(full_text.strip())\n",
    "        \n",
    "        results.extend(cleaned_outputs)\n",
    "    \n",
    "    df = df.copy()\n",
    "    df['SUMMARIZEDSOLUTION'] = results\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Optional function for a tokenized input length calculation\n",
    "\n",
    "def calculate_token_length(tokenizer, df, query_column, answer_column, instruction_prompt,\n",
    "                               examples = None, batch_size = 4, long_text_threshold = 4000):\n",
    "    \n",
    "    results = []\n",
    "    conversation = []\n",
    "    \n",
    "    # Build few-shot prompt\n",
    "    \n",
    "    if examples:\n",
    "        for inp, out in examples:\n",
    "            conversation.append({'role' : 'user', 'content' : inp})\n",
    "            conversation.append({'role' : 'assistant', 'content' : out})\n",
    "\n",
    "    # System role\n",
    "    \n",
    "    conversation.insert(0, {'role' : 'system', 'content' : instruction_prompt})\n",
    "    \n",
    "    # Iterate over batches\n",
    "    \n",
    "    for start in range(0, len(df), batch_size):\n",
    "        \n",
    "        batch_texts = (df[query_column].iloc[start:start+batch_size] + '\\n\\n' +\n",
    "                           df[answer_column].iloc[start:start+batch_size]).tolist()\n",
    "        \n",
    "        # Build prompts for batch\n",
    "        \n",
    "        prompts = [\n",
    "            tokenizer.apply_chat_template(\n",
    "                conversation = conversation + [{'role' : 'user', 'content': re.sub(r'\\s+', ' ',text).strip()}],\n",
    "                add_generation_prompt = True,\n",
    "                tokenize = False) \\\n",
    "            for text in batch_texts\n",
    "        ]\n",
    "            \n",
    "        # Tokenize\n",
    "        \n",
    "        inputs = tokenizer(prompts, return_tensors = 'pt', padding = True, truncation = False, padding_side = 'left').to(DEVICE)\n",
    "    \n",
    "        length = inputs['attention_mask'].sum(axis = 1).tolist()\n",
    "    \n",
    "        results.extend(length)\n",
    "\n",
    "    df['combined_case_token_length'] = np.array(results)\n",
    "    df['is_long'] = df['combined_case_token_length'] >= long_text_threshold\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72c9897e-f38b-4af1-a3fd-49aab79d49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configuration and import parameters\n",
    "\n",
    "FROM_PRETRAINED = False\n",
    "IS_DUMMY = True\n",
    "DUMMY_PARAMETERS = {'hidden_size' : 2, 'intermediate_size' : 4, 'head_dim' : 8}\n",
    "\n",
    "USE_GPU = False\n",
    "DEVICE = torch.device('mps' if torch.mps.is_available() and USE_GPU else ('cuda:0' if torch.cuda.is_available() and USE_GPU else 'cpu'))\n",
    "\n",
    "MODEL_DICT = \\\n",
    "    {'name' : 'Llama-3-8B-Instruct',\n",
    "     'repo_id' : 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "     'required_files' : ['config.json', 'generation_config.json', 'model.safetensors',\n",
    "                         'model-00001-of-00004.safetensors', 'model-00002-of-00004.safetensors',\n",
    "                         'model-00003-of-00004.safetensors', 'model-00004-of-00004.safetensors',\n",
    "                         'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'model.safetensors.index.json'],\n",
    "     'model_path' : ['LLaMa', '3.1-8B-Instruct']}\n",
    "\n",
    "# Model and data paths \n",
    "\n",
    "llm_path = Path.cwd().joinpath(*MODEL_DICT['model_path'])\n",
    "data_folder = Path.cwd().joinpath('Data')\n",
    "\n",
    "# Upload data\n",
    "\n",
    "processed_tickets_df = pd.read_json(data_folder.joinpath('processed_tickets_df.json'),\n",
    "                                        orient = 'index', typ = 'frame',\n",
    "                                            dtype = str, precise_float = True)\n",
    "\n",
    "# Upload auxiliary files \n",
    "\n",
    "with open(data_folder.joinpath('instruction_prompt_preprocessing.txt')) as ip, \\\n",
    "    open(data_folder.joinpath('examples.txt')) as e:\n",
    "        \n",
    "    instruction_prompt = ip.read()\n",
    "    examples = e.read()\n",
    "\n",
    "examples = [(example.split('|<[sep1]>|')[0].strip(), example.split('|<[sep1]>|')[1].strip())\n",
    "                for example in examples.split('|<[sep2]>|')]\n",
    "\n",
    "# Upload a model\n",
    "\n",
    "tokenizer, llm_model, gen_config = \\\n",
    "    load_model(llm_path, DEVICE,\n",
    "               load_8bit = False, from_pretrained = False,\n",
    "               is_dummy = True, dummy_parameters = DUMMY_PARAMETERS,\n",
    "               rope_scaling = {'type': 'linear', 'factor': 4.0}, max_context_length = 32768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b0a8183-e383-4b41-8e21-dbd9010671ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [07:02<00:00, 140.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# Apply data transformation\n",
    "\n",
    "processed_tickets_df = \\\n",
    "    batch_inference_llama(llm_model, tokenizer, processed_tickets_df,\n",
    "                          'STRUCTUREDPROBLEM', 'STRUCTUREDSOLUTION',\n",
    "                          instruction_prompt, gen_config,\n",
    "                          examples = examples, batch_size = 4, max_new_tokens = 1024, num_examples = 3)\n",
    "\n",
    "processed_tickets_df.to_json(data_folder.joinpath('llm_processed_tickets_df.json'),\n",
    "                                 orient = 'index', double_precision = 15, index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4432c04e-d2b0-4bcc-b74c-3849afd61b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally execute a check for tokenized input lengths\n",
    "\n",
    "processed_tickets_length_df = \\\n",
    "    calculate_token_length(tokenizer, processed_tickets_df,\n",
    "                           'STRUCTUREDPROBLEM', 'STRUCTUREDSOLUTION',\n",
    "                           instruction_prompt, examples = examples, batch_size = 4,\n",
    "                           long_text_threshold = 4000)\n",
    "\n",
    "processed_tickets_length_df.to_excel(data_folder.joinpath('combined_case_token_lengths.xlsx'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2c018-9105-4ba7-84c8-071b1c1764e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
