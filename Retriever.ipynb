{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb2b19d-bc1f-45ad-85b1-063be474ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoModelForCausalLM, AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from huggingface_hub import login\n",
    "from safetensors.torch import load_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d7c1d-9150-4a85-9dec-c3a658b86804",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a320b-cf0a-4b23-a4b8-0367927ca6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "\n",
    "filename = 'processed_tickets_df.json'\n",
    "data_folder = Path.cwd().joinpath('Data')\n",
    "\n",
    "processed_tickets_df = pd.read_json(data_folder.joinpath(filename), \n",
    "                                    orient = 'index', typ = 'frame', \n",
    "                                    dtype = str, precise_float = True)\n",
    "\n",
    "processed_tickets_df.drop(columns = ['PROBLEM', 'SOLUTION'], inplace = True)\n",
    "processed_tickets_df.rename(columns = {'STRUCTUREDPROBLEM' : 'PROBLEM', 'STRUCTUREDSOLUTION' : 'SOLUTION'}, inplace = True)\n",
    "\n",
    "processed_tickets_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bdbd4e-f62a-4dc7-8c41-3ed1407b0cdd",
   "metadata": {},
   "source": [
    "## Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8137a870-1d9c-408f-ad7c-e8c57cd9b16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfe5d9fe601499dbe8714e581ca8c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b3924bcad24d578a5f2879f61e2e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07be8a45422942a180f66a795258a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41801c6a09c44e62b2ac3c4f39397506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17519aee2a2484681d8277eda3937f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16e677a24fb4e91b5407f1e39a93135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e716ed87415745c8b3ad0ab24f32e63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7fad196b2242108c2cfd4376abe043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de52dcbe7ef4ca0ad5ea0d3e8b0975a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model configuration and import parameters\n",
    "\n",
    "USE_GPU = False\n",
    "DEVICE = torch.device('mps' if torch.mps.is_available() and USE_GPU else ('cuda' if torch.cuda.is_available() and USE_GPU else 'cpu'))\n",
    "\n",
    "MODEL_NUM = 0\n",
    "MODEL_DICT = \\\n",
    "    [\n",
    "        {'name' : 'SBERT-all-MiniLM-L12-v2',\n",
    "         'repo_id' : 'sentence-transformers/all-MiniLM-L12-v2',\n",
    "         'required_files' : ['config.json', 'config_sentence_transformers.json', 'data_config.json',\n",
    "                             'sentence_bert_config.json', 'tokenizer_config.json', 'special_tokens_map.json',\n",
    "                             'model.safetensors', 'modules.json', 'tokenizer.json'],\n",
    "         'model_path' : ['SBERT', 'all-MiniLM-L12-v2']\n",
    "        },\n",
    "        \n",
    "        {'name' : 'SBERT-all-mpnet-base-v2',\n",
    "         'repo_id' : 'sentence-transformers/all-mpnet-base-v2',\n",
    "         'required_files' : ['config.json', 'config_sentence_transformers.json', 'data_config.json',\n",
    "                             'sentence_bert_config.json', 'tokenizer_config.json', 'special_tokens_map.json',\n",
    "                             'model.safetensors', 'modules.json', 'tokenizer.json'],\n",
    "         'model_path' : ['SBERT', 'all-mpnet-base-v2']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Model import\n",
    "\n",
    "llm_path = Path.cwd().joinpath(*MODEL_DICT[MODEL_NUM]['model_path'])\n",
    "llm_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# Optional download of config files and parameters\n",
    "\n",
    "if not llm_path.joinpath(MODEL_DICT[MODEL_NUM]['model_path'][0]).exists():\n",
    "    snapshot_download(repo_id = MODEL_DICT[MODEL_NUM]['repo_id'], allow_patterns = MODEL_DICT[MODEL_NUM]['required_files'], \n",
    "                          local_dir = llm_path, use_auth_token = True)\n",
    "\n",
    "# Instantiate the model\n",
    "\n",
    "llm_model = AutoModel.from_pretrained(llm_path, local_files_only = True, use_safetensors = True).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_path, local_files_only = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "213d99b6-04f6-458d-b940-8c7648027297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace pooling logic\n",
    "\n",
    "class BertAttentionPooler(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, device):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.attention_mask = None\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.key = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        self.dimension_scaling = torch.sqrt(torch.tensor(config.hidden_size))\n",
    "        \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "        # Initialize weights and move to device\n",
    "\n",
    "        self.apply(lambda module: self.init_weights(module, config.initializer_range, device))\n",
    "\n",
    "    def init_weights(self, module, initializer_range, device):\n",
    "        \n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean = 0.0, std = initializer_range)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "\n",
    "        module.to(device)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        query_embeds = self.query(hidden_states)\n",
    "        key_embeds = self.key(hidden_states)\n",
    "        \n",
    "        scaled_dot = (query_embeds * key_embeds).sum(dim = -1) / self.dimension_scaling\n",
    "\n",
    "        if not isinstance(self.attention_mask, torch.Tensor) or self.attention_mask.size()[:2] != hidden_states.size()[:2]:\n",
    "            self.attention_mask = torch.ones(hidden_states.size()[:2], device = hidden_states.device)\n",
    "            \n",
    "        mask = self.attention_mask == 0\n",
    "        scaled_dot = scaled_dot.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        pool_weights = self.softmax(scaled_dot).unsqueeze(-1)\n",
    "\n",
    "        pooled_output = (pool_weights * hidden_states).sum(dim = 1)\n",
    "        \n",
    "        pooled_output = self.dense(pooled_output)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "\n",
    "        self.attention_mask = None\n",
    "        \n",
    "        return pooled_output\n",
    "\n",
    "llm_model_q = llm_model\n",
    "llm_model_a  = copy.deepcopy(llm_model)\n",
    "\n",
    "llm_model_q.pooler = BertAttentionPooler(llm_model_q.config, DEVICE)\n",
    "llm_model_a.pooler = BertAttentionPooler(llm_model_a.config, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d11d7a-ee76-482e-97d8-94713dd25b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertAttentionPooler(\n",
       "    (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110221f1-68f9-4191-bcb9-48a65a3900a9",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36a1b466-f066-488d-a128-99f19c12f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a special dataset class for fine-tuning\n",
    "\n",
    "class RetrievalDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, dataset, query_col, answer_col, example_id_col, train = True):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train = train\n",
    "        self.samples = list((db_id, query, answer) for db_id, query, answer in \\\n",
    "                                zip(dataset[example_id_col].tolist(), dataset[query_col].tolist(),\n",
    "                                        dataset[answer_col].tolist()))\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        db_id, query, answer = self.samples[idx]\n",
    "\n",
    "        # Tokenize text\n",
    "            \n",
    "        encoding_q = self.tokenizer(query, return_tensors = 'pt', add_special_tokens = False, truncation = True, max_length = 512)\n",
    "        encoding_a = self.tokenizer(answer, return_tensors = 'pt', add_special_tokens = False, truncation = True, max_length = 512)\n",
    "        \n",
    "        input_ids_q = encoding_q['input_ids'].squeeze(0)\n",
    "        input_ids_a = encoding_a['input_ids'].squeeze(0)\n",
    "\n",
    "        return input_ids_q, input_ids_a, query, answer, self.train, db_id\n",
    "\n",
    "    def batch_collate(self, batch):\n",
    "        \n",
    "        input_ids_q, input_ids_a, query, answer, is_train, db_id = zip(*batch)\n",
    "        \n",
    "        input_ids_q = nn.utils.rnn.pad_sequence(input_ids_q, batch_first = True, padding_value = self.tokenizer.pad_token_id)\n",
    "        input_ids_a = nn.utils.rnn.pad_sequence(input_ids_a, batch_first = True, padding_value = self.tokenizer.pad_token_id)\n",
    "        \n",
    "        attention_mask_q = (input_ids_q != self.tokenizer.pad_token_id).to(torch.long)\n",
    "        attention_mask_a = (input_ids_a != self.tokenizer.pad_token_id).to(torch.long)\n",
    "        \n",
    "        return input_ids_q, input_ids_a, attention_mask_q, attention_mask_a, query, answer, is_train, db_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d80b7fb5-9ecb-4f86-b8db-5db81477f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataset and data loading\n",
    "\n",
    "validation = False\n",
    "validation_share = 0.1\n",
    "batch_size = 32\n",
    "\n",
    "if validation:\n",
    "\n",
    "    validation_idx = np.random.choice(list(processed_tickets_df.index),\n",
    "                                      int(len(processed_tickets_df.index) * validation_share), replace = False)\n",
    "    validation_mask = processed_tickets_df.index.isin(validation_idx)\n",
    "\n",
    "    dataset_train = RetrievalDataset(tokenizer, processed_tickets_df[~validation_mask], 'PROBLEM', 'SOLUTION', 'TICKETID', train = True)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle = True, collate_fn = dataset_train.batch_collate)\n",
    "\n",
    "    dataset_val = RetrievalDataset(tokenizer, processed_tickets_df[validation_mask], 'PROBLEM', 'SOLUTION', 'TICKETID', train = False)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size = batch_size, shuffle = True, collate_fn = dataset_val.batch_collate)\n",
    "    \n",
    "else:\n",
    "\n",
    "    dataset_train = RetrievalDataset(tokenizer, processed_tickets_df, 'PROBLEM', 'SOLUTION', 'TICKETID', train = True)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle = True, collate_fn = dataset_train.batch_collate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559be1c1-267c-4639-93a2-56237883165c",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dca4af30-7c3f-4955-9d75-69cb539f741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer definition\n",
    "\n",
    "# Learning rate hyperparameters\n",
    "\n",
    "embed_base_lr_q = 1e-5\n",
    "encoder_base_lr_q = 2e-5\n",
    "head_base_lr_q = 5e-5\n",
    "\n",
    "embed_base_lr_a = 2e-5\n",
    "encoder_base_lr_a = 5e-5\n",
    "head_base_lr_a = 1e-4\n",
    "\n",
    "# Weight decay hyperparameters\n",
    "\n",
    "weight_decay = 0.01\n",
    "lr_layer_decay = 0.95\n",
    "\n",
    "# Scheduling and regularization hyperparameters\n",
    "\n",
    "epochs = 10\n",
    "warmup = 0.05\n",
    "num_training_steps = int(np.ceil((len(dataset_train) / batch_size) * epochs))\n",
    "num_warmup_steps = int(np.ceil(num_training_steps * warmup))\n",
    "\n",
    "# Temperature parameter\n",
    "\n",
    "tau_sim = 0.07\n",
    "\n",
    "# Construction of parameter-specific learning rates and weight decays\n",
    "\n",
    "def prepare_training_params(model, embed_base_lr, encoder_base_lr, head_base_lr, weight_decay, lr_layer_decay):\n",
    "\n",
    "    parameter_optim_list = []\n",
    "    num_layers = len(model.encoder.layer)\n",
    "    \n",
    "    param_dict = {\n",
    "        'embeddings' : [*model.embeddings.parameters()],\n",
    "        'encoder' : [[*model.encoder.layer[i].parameters()] for i in range(num_layers)],\n",
    "        'pooler' : [*model.pooler.parameters()]\n",
    "    }\n",
    "    \n",
    "    for key, value in param_dict.items():\n",
    "    \n",
    "        if key == 'pooler':\n",
    "            parameter_optim_list.append(\n",
    "                {'params' : value,\n",
    "                 'weight_decay': weight_decay,\n",
    "                 'lr': head_base_lr\n",
    "                })\n",
    "        \n",
    "        elif key == 'embeddings':\n",
    "            parameter_optim_list.append(\n",
    "                {'params' : value,\n",
    "                 'weight_decay': weight_decay,\n",
    "                 'lr': embed_base_lr\n",
    "                })    \n",
    "            \n",
    "        elif key == 'encoder':\n",
    "            for i in range(len(value)):\n",
    "                parameter_optim_list.append(\n",
    "                    {'params' : value[i],\n",
    "                     'weight_decay': weight_decay,\n",
    "                     'lr': encoder_base_lr * (lr_layer_decay ** (num_layers - (i + 1)))\n",
    "                    })\n",
    "                \n",
    "    return parameter_optim_list\n",
    "\n",
    "parameter_optim_list_q = prepare_training_params(llm_model_q, embed_base_lr_q, encoder_base_lr_q,\n",
    "                                                     head_base_lr_q, weight_decay, lr_layer_decay)\n",
    "parameter_optim_list_a = prepare_training_params(llm_model_a, embed_base_lr_a, encoder_base_lr_a,\n",
    "                                                     head_base_lr_a, weight_decay, lr_layer_decay)\n",
    "\n",
    "# Optimizer instantiation\n",
    "\n",
    "encoder_optimizer_q = optim.AdamW(parameter_optim_list_q[0:-1])\n",
    "pooler_optimizer_q = optim.AdamW([parameter_optim_list_q[-1]])\n",
    "\n",
    "encoder_optimizer_a = optim.AdamW(parameter_optim_list_a[0:-1])\n",
    "pooler_optimizer_a = optim.AdamW([parameter_optim_list_a[-1]])\n",
    "\n",
    "# Learning rate scheduler instantiation\n",
    "\n",
    "def get_schedule(optimizer, num_warmup_steps, num_training_steps, original,\n",
    "                     num_cycles = 0.5, min_lambda_lr = 0.1, lr_scaling_power = 2):\n",
    "\n",
    "    if original:\n",
    "\n",
    "        def lr_lambda(current_step):\n",
    "\n",
    "            current_val = current_step ** lr_scaling_power\n",
    "            max_val = num_training_steps ** lr_scaling_power\n",
    "            \n",
    "            return max(0, current_val / max_val)\n",
    "\n",
    "    else:\n",
    "\n",
    "        def lr_lambda(current_step):\n",
    "            \n",
    "            if current_step < num_warmup_steps:\n",
    "                return float(current_step) / float(max(1, num_warmup_steps))\n",
    "            progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "            \n",
    "            return max(min_lambda_lr , 0.5 * (1.0 + torch.cos(torch.tensor(num_cycles * torch.pi * 2.0 * progress))))\n",
    "    \n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "scheduler_encoder_q = get_schedule(\n",
    "    encoder_optimizer_q, \n",
    "    num_warmup_steps = num_warmup_steps, \n",
    "    num_training_steps = num_training_steps,\n",
    "    original = True\n",
    ")\n",
    "\n",
    "scheduler_pooler_q = get_schedule(\n",
    "    pooler_optimizer_q, \n",
    "    num_warmup_steps = num_warmup_steps, \n",
    "    num_training_steps = num_training_steps,\n",
    "    original = False\n",
    ")\n",
    "\n",
    "scheduler_encoder_a = get_schedule(\n",
    "    encoder_optimizer_a, \n",
    "    num_warmup_steps = num_warmup_steps, \n",
    "    num_training_steps = num_training_steps,\n",
    "    original = True\n",
    ")\n",
    "\n",
    "scheduler_pooler_a = get_schedule(\n",
    "    pooler_optimizer_a, \n",
    "    num_warmup_steps = num_warmup_steps, \n",
    "    num_training_steps = num_training_steps,\n",
    "    original = False\n",
    ")\n",
    "\n",
    "# Define a loss function\n",
    "\n",
    "def infoNCE_loss_fn(embed_q, embed_a, tau_sim):\n",
    "\n",
    "    q_norm = nn.functional.normalize(embed_q, p = 2, dim = -1)\n",
    "    a_norm = nn.functional.normalize(embed_a, p = 2, dim = -1)\n",
    "    \n",
    "    sim = torch.einsum('ae,be->ab', q_norm, a_norm) / tau_sim\n",
    "    \n",
    "    loss = -torch.diag(sim) + torch.logsumexp(sim, dim = 1)\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "    \n",
    "# Model checkpointing utility\n",
    "\n",
    "trained_model_q_output_dir = llm_path.joinpath('q_encoder', f\"Checkpoint_{MODEL_DICT[MODEL_NUM]['name']}\")\n",
    "trained_model_a_output_dir = llm_path.joinpath('a_encoder', f\"Checkpoint_{MODEL_DICT[MODEL_NUM]['name']}\")\n",
    "txt_filename = 'fine_tuning_report.txt'\n",
    "\n",
    "txt_template = \\\n",
    "\"\"\"\n",
    "//Fine-tuning checkpoint//\n",
    "\n",
    "Datetime: {0}\n",
    "Last training step: {1}\n",
    "Last epoch: {2}\n",
    "Epoch train losses: {3}\n",
    "Epoch validation losses: {4}\n",
    "Checkpoint source: {5}\n",
    "\n",
    "Last batch infoNCE losses: {6}\n",
    "\n",
    "//Hyperparameters//\n",
    "\n",
    "Query embedding base learning rate: {7}\n",
    "Query encoder base learning rate: {8}\n",
    "Query pooler base learning rate: {9}\n",
    "\n",
    "Answer embedding base learning rate: {10}\n",
    "Answer encoder base learning rate: {11}\n",
    "Answer pooler base learning rate: {12}\n",
    "\n",
    "Similarity loss temperature: {13}\n",
    "Weight decay: {14}\n",
    "Layer learning rate decay: {15}\n",
    "LR Warmup: {16}\n",
    "LR Sheduling: One cycle cosine annealing (Pooler) + Squared growth annealing (Embedding and Encoder)\n",
    "Max number of epochs: {17}\n",
    "Batch size: {18}\n",
    "\"\"\"\n",
    "\n",
    "def save_model_checkpoint(model_q: PreTrainedModel, model_a: PreTrainedModel,\n",
    "                              tokenizer: PreTrainedTokenizer, output_dir_q: str, output_dir_a: str,\n",
    "                                  txt_filename: str, txt_template: str, log_param_list : list):\n",
    "\n",
    "    txt_log = txt_template.format(*log_param_list)\n",
    "    \n",
    "    os.makedirs(output_dir_q, exist_ok = True)\n",
    "    os.makedirs(output_dir_a, exist_ok = True)\n",
    "    \n",
    "    model_q.save_pretrained(output_dir_q, safe_serialization = True)\n",
    "    model_a.save_pretrained(output_dir_a, safe_serialization = True) \n",
    "    \n",
    "    tokenizer.save_pretrained(output_dir_q)\n",
    "    tokenizer.save_pretrained(output_dir_a)\n",
    "\n",
    "    with open(output_dir_q.joinpath(txt_filename), 'w') as qf, \\\n",
    "             open(output_dir_a.joinpath(txt_filename), 'w') as af:\n",
    "        qf.write(txt_log)\n",
    "        af.write(txt_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85025b49-b919-4ae5-88f3-25c38bbc1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fine-tuning loop\n",
    "\n",
    "# Hyper-parameters\n",
    "\n",
    "validation_logging_factor = 1\n",
    "gradient_accumulation = 1\n",
    "checkpoint_frequency_steps = 100\n",
    "\n",
    "tolerance = 0\n",
    "patience = 2\n",
    "\n",
    "best_score = np.inf\n",
    "patience_epochs = 0\n",
    "training_steps = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Training\n",
    "\n",
    "    epoch_loss = []\n",
    "    llm_model_q.train()\n",
    "    llm_model_a.train()\n",
    "    \n",
    "    for input_ids_q, input_ids_a, attention_mask_q, attention_mask_a, _, _, _, _ in tqdm(dataloader_train):\n",
    "        \n",
    "        input_ids_q = input_ids_q.to(llm_model_q.device)\n",
    "        attention_mask_q = attention_mask_q.to(llm_model_q.device)\n",
    "\n",
    "        input_ids_a = input_ids_a.to(llm_model_a.device)\n",
    "        attention_mask_a = attention_mask_a.to(llm_model_a.device)\n",
    "\n",
    "        llm_model_q.pooler.attention_mask = attention_mask_q\n",
    "        llm_model_a.pooler.attention_mask = attention_mask_a\n",
    "\n",
    "        embed_q = llm_model_q(input_ids_q, attention_mask = attention_mask_q).pooler_output\n",
    "        embed_a = llm_model_a(input_ids_a, attention_mask = attention_mask_a).pooler_output\n",
    "        \n",
    "        loss =  infoNCE_loss_fn(embed_q, embed_a, tau_sim) / gradient_accumulation\n",
    "        loss_unnorm = loss.item() * gradient_accumulation\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        training_steps += 1\n",
    "        if training_steps % gradient_accumulation == 0:\n",
    "\n",
    "            encoder_optimizer_q.step()\n",
    "            pooler_optimizer_q.step()\n",
    "            encoder_optimizer_a.step()\n",
    "            pooler_optimizer_a.step()\n",
    "\n",
    "            scheduler_encoder_q.step()\n",
    "            scheduler_pooler_q.step()\n",
    "            scheduler_encoder_a.step()\n",
    "            scheduler_pooler_a.step()\n",
    "            \n",
    "            encoder_optimizer_q.zero_grad()\n",
    "            pooler_optimizer_q.zero_grad()\n",
    "            encoder_optimizer_a.zero_grad()\n",
    "            pooler_optimizer_a.zero_grad()\n",
    "\n",
    "        epoch_loss.append(loss_unnorm)\n",
    "\n",
    "        if training_steps % checkpoint_frequency_steps == 0:\n",
    "\n",
    "            checkpoint_source = 'Ongoing intermediate checkpointing'\n",
    "            log_list = \\\n",
    "                [str(datetime.datetime.now()), training_steps, epoch + 1,\n",
    "                 str(train_losses), str(val_losses), checkpoint_source, str(epoch_loss),\n",
    "                 embed_base_lr_q, encoder_base_lr_q, head_base_lr_q, embed_base_lr_a, encoder_base_lr_a, head_base_lr_a,\n",
    "                 tau_sim, weight_decay, lr_layer_decay, warmup, epochs, batch_size]\n",
    "            save_model_checkpoint(llm_model_q, llm_model_a, tokenizer, trained_model_q_output_dir,\n",
    "                                      trained_model_a_output_dir, txt_filename, txt_template, log_list)\n",
    "\n",
    "    train_losses.append(torch.tensor(epoch_loss).mean().item())\n",
    "    print(f'Epoch {epoch + 1} train loss: {torch.tensor(epoch_loss).mean().item():.4f}')\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    if epoch % validation_logging_factor == 0 and validation:\n",
    "    \n",
    "        epoch_loss = []\n",
    "        llm_model_q.eval()\n",
    "        llm_model_a.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            for input_ids_q, input_ids_a, attention_mask_q, attention_mask_a, _, _, _, _ in dataloader_val:\n",
    "                \n",
    "                input_ids_q = input_ids_q.to(llm_model_q.device)\n",
    "                attention_mask_q = attention_mask_q.to(llm_model_q.device)\n",
    "        \n",
    "                input_ids_a = input_ids_a.to(llm_model_a.device)\n",
    "                attention_mask_a = attention_mask_a.to(llm_model_a.device)\n",
    "\n",
    "                llm_model_q.pooler.attention_mask = attention_mask_q\n",
    "                llm_model_a.pooler.attention_mask = attention_mask_a\n",
    "        \n",
    "                embed_q = llm_model_q(input_ids_q, attention_mask = attention_mask_q).pooler_output\n",
    "                embed_a = llm_model_a(input_ids_a, attention_mask = attention_mask_a).pooler_output\n",
    "                \n",
    "                loss =  infoNCE_loss_fn(embed_q, embed_a, tau_sim)\n",
    "        \n",
    "                epoch_loss.append(loss.item())\n",
    "        \n",
    "            val_losses.append(torch.tensor(epoch_loss).mean().item())\n",
    "            print(f'Epoch {epoch + 1} validation loss: {torch.tensor(epoch_loss).mean().item():.4f}')\n",
    "\n",
    "    else:\n",
    "\n",
    "        val_losses.append(np.nan)\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if validation:\n",
    "\n",
    "        if not np.isnan(val_losses[-1]) and val_losses[-1] < best_score * (1 + tolerance):\n",
    "            best_score = val_losses[-1]\n",
    "\n",
    "            checkpoint_source = 'Post validation improvement checkpointing'\n",
    "            log_list = \\\n",
    "                [str(datetime.datetime.now()), training_steps, epoch + 1,\n",
    "                 str(train_losses), str(val_losses), checkpoint_source, str(epoch_loss),\n",
    "                 embed_base_lr_q, encoder_base_lr_q, head_base_lr_q, embed_base_lr_a, encoder_base_lr_a, head_base_lr_a,\n",
    "                 tau_sim, weight_decay, lr_layer_decay, warmup, epochs, batch_size]\n",
    "            save_model_checkpoint(llm_model_q, llm_model_a, tokenizer, trained_model_q_output_dir,\n",
    "                                      trained_model_a_output_dir, txt_filename, txt_template, log_list)\n",
    "            patience_epochs = 0\n",
    "            \n",
    "        elif not np.isnan(val_losses[-1]) and val_losses[-1] >= best_score * (1 + tolerance):\n",
    "            patience_epochs += 1\n",
    "            if patience_epochs >= patience:\n",
    "                print('Early stopping triggered!')\n",
    "                break\n",
    "\n",
    "    elif (epoch + 1) == epochs:\n",
    "\n",
    "        checkpoint_source = 'Final training checkpoint'\n",
    "        log_list = \\\n",
    "            [str(datetime.datetime.now()), training_steps, epoch + 1,\n",
    "             str(train_losses), str(val_losses), checkpoint_source, str(epoch_loss),\n",
    "             embed_base_lr_q, encoder_base_lr_q, head_base_lr_q, embed_base_lr_a, encoder_base_lr_a, head_base_lr_a,\n",
    "             tau_sim, weight_decay, lr_layer_decay, warmup, epochs, batch_size]\n",
    "        save_model_checkpoint(llm_model_q, llm_model_a, tokenizer, trained_model_q_output_dir,\n",
    "                                  trained_model_a_output_dir, txt_filename, txt_template, log_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39d6bd-0688-420c-b086-249687e443c4",
   "metadata": {},
   "source": [
    "## Embeddings generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b633be9-bc12-425a-beab-ac4ec8477ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configuration and import parameters\n",
    "\n",
    "USE_GPU = False\n",
    "DEVICE = torch.device('mps' if torch.mps.is_available() and USE_GPU else ('cuda' if torch.cuda.is_available() and USE_GPU else 'cpu'))\n",
    "\n",
    "MODEL_NUM = 0\n",
    "MODEL_DICT = \\\n",
    "    [\n",
    "        {'name' : 'SBERT-all-MiniLM-L12-v2',\n",
    "         'repo_id' : 'sentence-transformers/all-MiniLM-L12-v2',\n",
    "         'required_files' : ['config.json', 'config_sentence_transformers.json', 'data_config.json',\n",
    "                             'sentence_bert_config.json', 'tokenizer_config.json', 'special_tokens_map.json',\n",
    "                             'model.safetensors', 'modules.json', 'tokenizer.json'],\n",
    "         'model_path' : ['SBERT', 'all-MiniLM-L12-v2']\n",
    "        },\n",
    "        \n",
    "        {'name' : 'SBERT-all-mpnet-base-v2',\n",
    "         'repo_id' : 'sentence-transformers/all-mpnet-base-v2',\n",
    "         'required_files' : ['config.json', 'config_sentence_transformers.json', 'data_config.json',\n",
    "                             'sentence_bert_config.json', 'tokenizer_config.json', 'special_tokens_map.json',\n",
    "                             'model.safetensors', 'modules.json', 'tokenizer.json'],\n",
    "         'model_path' : ['SBERT', 'all-mpnet-base-v2']\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Model import\n",
    "\n",
    "llm_path = Path.cwd().joinpath(*MODEL_DICT[MODEL_NUM]['model_path'])\n",
    "trained_model_q_output_dir = llm_path.joinpath('q_encoder', f\"Checkpoint_{MODEL_DICT[MODEL_NUM]['name']}\")\n",
    "trained_model_a_output_dir = llm_path.joinpath('a_encoder', f\"Checkpoint_{MODEL_DICT[MODEL_NUM]['name']}\")\n",
    "\n",
    "def import_dual_BERT_encoder(llm_path, encoder_q_path, encoder_a_path, DEVICE):\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(llm_path, local_files_only = True)\n",
    "    llm_model_q = AutoModel.from_config(config).to(DEVICE)\n",
    "    llm_model_a = copy.deepcopy(llm_model_q).to(DEVICE)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(llm_path, local_files_only = True)\n",
    "\n",
    "    llm_model_q.pooler = BertAttentionPooler(llm_model_q.config, DEVICE)\n",
    "    llm_model_a.pooler = BertAttentionPooler(llm_model_a.config, DEVICE)\n",
    "\n",
    "    state_dict_q = {}\n",
    "    state_dict_a = {}\n",
    "    \n",
    "    for file in os.listdir(encoder_q_path):\n",
    "        if file.split('.')[-1] == 'safetensors':      \n",
    "            state_dict = load_file(encoder_q_path.joinpath(file))\n",
    "            state_dict_q.update(state_dict)\n",
    "    with warnings.catch_warnings(action = 'ignore'):\n",
    "        llm_model_q.load_state_dict(state_dict_q, strict = True)\n",
    "\n",
    "    for file in os.listdir(encoder_a_path):\n",
    "        if file.split('.')[-1] == 'safetensors':      \n",
    "            state_dict = load_file(encoder_a_path.joinpath(file))\n",
    "            state_dict_a.update(state_dict)\n",
    "    with warnings.catch_warnings(action = 'ignore'):\n",
    "        llm_model_a.load_state_dict(state_dict_a, strict = True)\n",
    "\n",
    "    return llm_model_q, llm_model_a, tokenizer\n",
    "\n",
    "llm_model_q, llm_model_a, tokenizer = import_dual_BERT_encoder(llm_path, trained_model_q_output_dir, trained_model_a_output_dir, DEVICE)\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset = RetrievalDataset(tokenizer, processed_tickets_df, 'PROBLEM', 'SOLUTION', 'TICKETID', train = False)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = False, collate_fn = dataset.batch_collate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1db25476-0204-4432-8e89-90975f34f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector representations for all tickets (queries and answers separately)\n",
    "\n",
    "def embed_dataset(dataloader, encoder_q, encoder_a):\n",
    "\n",
    "    encoder_q.eval()\n",
    "    encoder_a.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        embed_q_list = []\n",
    "        embed_a_list = []\n",
    "        query_list = []\n",
    "        answer_list = []\n",
    "        db_id_list = []\n",
    "    \n",
    "        for input_ids_q, input_ids_a, attention_mask_q, attention_mask_a, query, answer, _, db_id in dataloader:\n",
    "            \n",
    "            input_ids_q = input_ids_q.to(encoder_q.device)\n",
    "            attention_mask_q = attention_mask_q.to(encoder_q.device)\n",
    "    \n",
    "            input_ids_a = input_ids_a.to(encoder_a.device)\n",
    "            attention_mask_a = attention_mask_a.to(encoder_a.device)\n",
    "    \n",
    "            encoder_q.pooler.attention_mask = attention_mask_q\n",
    "            encoder_a.pooler.attention_mask = attention_mask_a\n",
    "    \n",
    "            embed_q = encoder_q(input_ids_q, attention_mask = attention_mask_q).pooler_output\n",
    "            embed_a = encoder_a(input_ids_a, attention_mask = attention_mask_a).pooler_output\n",
    "\n",
    "            embed_q_list.extend(embed_q.tolist())\n",
    "            embed_a_list.extend(embed_a.tolist())\n",
    "            query_list.extend(query)\n",
    "            answer_list.extend(answer)\n",
    "            db_id_list.extend(db_id)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Query' : query_list,\n",
    "        'Answer' : answer_list,\n",
    "        'Query embedding' : embed_q_list,\n",
    "        'Answer embedding' : embed_a_list\n",
    "    }, index = db_id_list)\n",
    "\n",
    "ticket_embedded_df = embed_dataset(dataloader, llm_model_q, llm_model_a)\n",
    "ticket_embedded_df.to_json('Data/embedded_ticket_df.json', orient = 'index', double_precision = 15, index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e85f395-8d67-4913-a559-b3b206715ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Query embedding</th>\n",
       "      <th>Answer embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t6UJ9A00GHH8</th>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHH8\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "      <td>[0.09085216373205185, -0.07308325916528702, -0...</td>\n",
       "      <td>[0.030940523371100426, -0.11406989395618439, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6UJ9A00GFTK</th>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GFTK\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "      <td>[0.00729460921138525, -0.012972509488463402, 0...</td>\n",
       "      <td>[-0.05271889269351959, -0.01821071468293667, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6UJ9A00GGSG</th>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GGSG\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "      <td>[0.0737481489777565, 0.014548237435519695, 0.0...</td>\n",
       "      <td>[0.03250913321971893, -0.0711088553071022, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6UJ9A00GHDL</th>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHDL\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 1\\n  Re...</td>\n",
       "      <td>[0.06461172550916672, -0.011558311991393566, 0...</td>\n",
       "      <td>[-0.020230183377861977, 0.016113998368382454, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t6UJ9A00GHHG</th>\n",
       "      <td>Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHHG\\...</td>\n",
       "      <td>Solution metadata:\\n \\n  Urgency code: 3\\n  Re...</td>\n",
       "      <td>[-0.02997729554772377, 0.06212735176086426, -0...</td>\n",
       "      <td>[-0.045093242079019547, -0.022921917960047722,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Query  \\\n",
       "t6UJ9A00GHH8  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHH8\\...   \n",
       "t6UJ9A00GFTK  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GFTK\\...   \n",
       "t6UJ9A00GGSG  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GGSG\\...   \n",
       "t6UJ9A00GHDL  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHDL\\...   \n",
       "t6UJ9A00GHHG  Ticket metadata:\\n\\n  Ticket ID: t6UJ9A00GHHG\\...   \n",
       "\n",
       "                                                         Answer  \\\n",
       "t6UJ9A00GHH8  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...   \n",
       "t6UJ9A00GFTK  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...   \n",
       "t6UJ9A00GGSG  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...   \n",
       "t6UJ9A00GHDL  Solution metadata:\\n \\n  Urgency code: 1\\n  Re...   \n",
       "t6UJ9A00GHHG  Solution metadata:\\n \\n  Urgency code: 3\\n  Re...   \n",
       "\n",
       "                                                Query embedding  \\\n",
       "t6UJ9A00GHH8  [0.09085216373205185, -0.07308325916528702, -0...   \n",
       "t6UJ9A00GFTK  [0.00729460921138525, -0.012972509488463402, 0...   \n",
       "t6UJ9A00GGSG  [0.0737481489777565, 0.014548237435519695, 0.0...   \n",
       "t6UJ9A00GHDL  [0.06461172550916672, -0.011558311991393566, 0...   \n",
       "t6UJ9A00GHHG  [-0.02997729554772377, 0.06212735176086426, -0...   \n",
       "\n",
       "                                               Answer embedding  \n",
       "t6UJ9A00GHH8  [0.030940523371100426, -0.11406989395618439, -...  \n",
       "t6UJ9A00GFTK  [-0.05271889269351959, -0.01821071468293667, -...  \n",
       "t6UJ9A00GGSG  [0.03250913321971893, -0.0711088553071022, -0....  \n",
       "t6UJ9A00GHDL  [-0.020230183377861977, 0.016113998368382454, ...  \n",
       "t6UJ9A00GHHG  [-0.045093242079019547, -0.022921917960047722,...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_embedded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015693a-2465-42c7-b8b7-a43930c22459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
